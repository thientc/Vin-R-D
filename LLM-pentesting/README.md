
# Redteam with LLM
## 1. Redteam with LLM
- [Red teaming ChatGPT via Jailbreaking: Bias, Robustness, Reliability and Toxicity](https://arxiv.org/pdf/2301.12867)
- [Generative AI for pentesting: the good, the bad, the ugly](https://link.springer.com/article/10.1007/s10207-024-00835-x)
- [Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks](https://arxiv.org/html/2505.12786v1)

## 2. shellGPT experiments
- [shellGPT](test_shellGPT/README.md)
- [Mistral-7b model features](https://www.promptingguide.ai/models/mistral-7b)

## 3. strix experiments
- [strix](test_strix/README.md)

## 4. Cyber Autoagent experiments
- [Cyber Autoagent](test_Cyber-Autoagent/)

## 5. Cisco CodeGuard rules
- [CodeGuard Rules experiments](test_CodeGuard-rules/README.md)

## 6. Conclusions
- Complexity of projects: dependencies, response format of LLMs
- Dependence on reasoning ability of LLMs
- Automation vs. Human-in-the-loop